{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17650081",
   "metadata": {},
   "source": [
    "# Cleaning and Formatting Protein Mutation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91bbbe",
   "metadata": {},
   "source": [
    "## ProThermDB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca504b6c",
   "metadata": {},
   "source": [
    "## Dataset Stats\n",
    "\n",
    "Number of Entries = 31,470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457cca0",
   "metadata": {},
   "source": [
    "#### Importing Data and Dropping Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf7e460",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PROTEIN', 'UniProt_ID', 'MUTATION', 'SOURCE', 'PDB_wild',\n",
      "       'PDB_Chain_Mutation', 'pH', 'T_(C)', 'Tm_(C)', '∆Tm_(C)',\n",
      "       '∆H_(kcal/mol)', '∆G_(kcal/mol)', '∆∆G_(kcal/mol)',\n",
      "       '∆∆G_H2O_(kcal/mol)', 'STATE', 'REVERSIBILITY', 'PubMed_ID',\n",
      "       'REFERENCE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Jupyter notebook settings to see all data\n",
    "max_rows = None\n",
    "max_cols = None\n",
    "pd.set_option(\"display.max_rows\", max_rows, \"display.max_columns\", max_cols) \n",
    "\n",
    "# load unmodified dataset\n",
    "protherm_path = os.path.join(\"DBdata\", \"ProThermDB_30_JUN_21.tsv\")\n",
    "protherm_df = pd.read_csv(protherm_path,sep='\\t')\n",
    "\n",
    "# removes unneccessary columns\n",
    "col_to_drop = [\"NO\", \"SEC_STR\", \"ASA\", \"KEY_WORDS\", \"AUTHOR\", \"REMARKS\"]\n",
    "protherm_df = protherm_df.drop(columns=col_to_drop)\n",
    "\n",
    "print(protherm_df.columns) \n",
    "\n",
    "# add dataset label\n",
    "protherm_df.insert(0, \"DATABASE\", 'Protherm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35345d6a",
   "metadata": {},
   "source": [
    "#### Functions used to Clean and Cast Column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7703a245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function casts all values in specified columns to floats\n",
    "def cast_to_float(df, col_name_list):\n",
    "    for col in col_name_list:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df\n",
    "\n",
    "# function casts all values in specified columns to strings\n",
    "def cast_to_string(df, col_name_list):\n",
    "    for col in col_name_list:\n",
    "        df[col] = np.where(pd.isnull(df[col]),df[col],df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# function returns list w/ only mean values of column (e.g 50 (0.01) -> 50)\n",
    "def extract_mean_val_list(column):\n",
    "    column = column.fillna(\"-\")\n",
    "    values = column.str.split(\" \")\n",
    "    mean_vals = []\n",
    "    for val in values:\n",
    "        mean = val[0].strip(\" \")\n",
    "        if \"(\" in mean:\n",
    "            mean = mean[:mean.index(\"(\")]\n",
    "        if \">\" in mean or \"<\" in mean:\n",
    "            mean = \"-\"\n",
    "        if len(mean) == 0:\n",
    "            mean = \"-\"\n",
    "        if \"-\" in mean and mean.index(\"-\") != 0:\n",
    "            nums = mean.split(\"-\")\n",
    "            nums = [float(i) for i in nums]\n",
    "            mean = (nums[0] + nums[1]) / 2\n",
    "        mean_vals.append(mean)\n",
    "    return mean_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e1fdc",
   "metadata": {},
   "source": [
    "#### Cleaning dataframe columns using above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a57639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removes all error values from columns w/ experimental error data included\n",
    "protherm_df[\"Tm_(C)\"] = extract_mean_val_list(protherm_df[\"Tm_(C)\"])\n",
    "protherm_df[\"∆Tm_(C)\"] = extract_mean_val_list(protherm_df[\"∆Tm_(C)\"])\n",
    "protherm_df[\"∆H_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆H_(kcal/mol)\"])\n",
    "protherm_df[\"∆G_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆G_(kcal/mol)\"])\n",
    "protherm_df[\"∆∆G_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆∆G_(kcal/mol)\"])\n",
    "protherm_df[\"∆∆G_H2O_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆∆G_H2O_(kcal/mol)\"])\n",
    "\n",
    "# remove \"(Based on UniProt)\"  or \"(Based on UniProt and PBD)\" from MUTATION column\n",
    "split_mutation_col = protherm_df[\"MUTATION\"].str.split(\"(\")\n",
    "names = []\n",
    "for string in split_mutation_col:\n",
    "    mutation_name = string[0].strip(\" \")\n",
    "    names.append(mutation_name)\n",
    "protherm_df[\"MUTATION\"] = names\n",
    "\n",
    "# remove PMID from REFERENCE\n",
    "fixed_reference = []\n",
    "for string in protherm_df[\"REFERENCE\"]:\n",
    "    pmid_index = string.find(\"PMID\")\n",
    "    fixed_reference.append(string[0:pmid_index-1])\n",
    "protherm_df[\"REFERENCE\"] = fixed_reference\n",
    "\n",
    "# clear error DOI strings from \"PubMed_ID\" colum and cast to float\n",
    "correct_ids = []\n",
    "for value in protherm_df[\"PubMed_ID\"]:\n",
    "    if \"DOI\" in value or \"(\" in value:\n",
    "        value = \"-\"\n",
    "    correct_ids.append(value)\n",
    "protherm_df[\"PubMed_ID\"] = correct_ids      \n",
    "\n",
    "# creating MUTATED_CHAIN column\n",
    "protherm_df[\"MUTATED_CHAIN\"] = np.nan\n",
    "\n",
    "# temporarily replace NaN with \"-\" to avoid errors\n",
    "protherm_df[\"PDB_Chain_Mutation\"] = protherm_df[\"PDB_Chain_Mutation\"].fillna(\"-\")\n",
    "\n",
    "# extract mutated chain from PBD_CHAIN_MUTATION and add to MUTATED_CHAIN col\n",
    "protherm_df[\"PDB_Chain_Mutation\"] = protherm_df[\"PDB_Chain_Mutation\"].str.strip(\" \")\n",
    "split_chain_col = protherm_df[\"PDB_Chain_Mutation\"].str.split(\" \")\n",
    "chain = []\n",
    "chain_letters = []\n",
    "for string in split_chain_col:\n",
    "    if \"-\" in string:\n",
    "        to_add_chains = np.nan\n",
    "    else:\n",
    "        for val in string:\n",
    "            index = val.find(\"_\")\n",
    "            letter = val[index+1]\n",
    "            chain_letters.append(letter)\n",
    "            to_add_chains = \",\".join(chain_letters)\n",
    "    chain.append(to_add_chains)\n",
    "    chain_letters.clear()\n",
    "protherm_df[\"MUTATED_CHAIN\"] = chain\n",
    "\n",
    "# replace all \"-\" values with NaN\n",
    "protherm_df = protherm_df.replace(\"-\", np.nan)\n",
    "\n",
    "# cast experimental values + PubMed_ID to floats\n",
    "protherm_df = cast_to_float(protherm_df, [\"pH\", \"T_(C)\", \"Tm_(C)\", \"∆Tm_(C)\", \"∆H_(kcal/mol)\",\n",
    "                                          \"∆G_(kcal/mol)\", \"∆∆G_(kcal/mol)\", \"∆∆G_H2O_(kcal/mol)\",\n",
    "                                          \"PubMed_ID\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731a810",
   "metadata": {},
   "source": [
    "## ThermoMutDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218f650",
   "metadata": {},
   "source": [
    "Number of Entries = 13,348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e85b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATABASE', 'PROTEIN', 'SOURCE', 'KINGDOM', 'UniProt_ID', 'PDB_wild',\n",
      "       'PDB_mutant', 'MUTATION', 'MUTATED_CHAIN', 'T_(C)', 'pH', 'MEASURE',\n",
      "       'METHOD', '∆∆G_(kcal/mol)', '∆Tm_(C)', 'REFERENCE', 'PubMed_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load unmodified dataset\n",
    "thermo_path = os.path.join(\"DBdata\", \"thermomutdb.csv\")\n",
    "thermo_df = pd.read_csv(thermo_path)\n",
    "\n",
    "# removing unnecessary columns and add DATABASE column\n",
    "col_to_drop = [\"ID\", \"YEAR\", \"DOI\", \"OTHER_LINKS\", \"HYDRO\",\n",
    "               \"POS\", \"NEG\", \"ACC\", \"DON\", \"ARO\", \"SUL\", \"NEU\", \"SST\", \"RSA\", \"PHI\",\n",
    "               \"PSI\",\"RES_DEPTH\", \"CA_DEPTH\", \"RELATIVE_BFACTOR\", \"BLOSUM62\", \"PAM250\",\n",
    "               \"SEQ_Uniprot\", \"MUTATION_uniprot\", \"MUTATION_pdb\"]\n",
    "\n",
    "thermo_df = thermo_df.drop(columns=col_to_drop)\n",
    "thermo_df.insert(0, \"DATABASE\", 'ThermoMut')\n",
    "\n",
    "# convert temperature units / dTM units to match protherm db (K to C)\n",
    "thermo_df[\"TEMP\"] = thermo_df[\"TEMP\"] - 273.15\n",
    "\n",
    "# renaming and adding columns to match formatting of final dataset\n",
    "dictionary = {\"UNIPROT\": \"UniProt_ID\",\n",
    "        \"TEMP\": \"T_(C)\",\n",
    "        \"ddG\":\"∆∆G_(kcal/mol)\",\n",
    "        \"dTm\": \"∆Tm_(C)\",\n",
    "        \"PMID\": \"PubMed_ID\"}\n",
    "\n",
    "thermo_df.rename(columns=dictionary, inplace = True)\n",
    "print(thermo_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a176d99",
   "metadata": {},
   "source": [
    "## FireProtDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be737423",
   "metadata": {},
   "source": [
    "Number of Entries = 17,136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15691a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATABASE', 'PROTEIN', 'UniProt_ID', 'PDB_wild', 'MUTATED_CHAIN',\n",
      "       'POSITION', 'WILD_TYPE_RES', 'MUTATED_RES', '∆∆G_H2O_(kcal/mol)',\n",
      "       '∆Tm_(C)', 'is_curated', 'conservation', 'METHOD', 'MEASURE', 'pH',\n",
      "       'Tm_(C)', 'notes', 'PubMed_ID', 'datasets'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "fireprot_path = os.path.join(\"DBdata\", \"fireprotdb_results.csv\")\n",
    "fireprot_df = pd.read_csv(fireprot_path, dtype=\"unicode\")\n",
    "\n",
    "# dropping unneccessary cols\n",
    "col_to_drop = [\"experiment_id\", \"type\", \"derived_type\", \"is_essential\", \"secondary_structure\", \"asa\", \"b_factor\",\n",
    "               \"method_details\", \"technique_details\", \"publication_doi\", \"hsw_job_id\", \"sequence\", \n",
    "               \"interpro_families\", \"correlated_pairs\", \"back_to_consensus\", \"is_in_catalytic_pocket\",\n",
    "               \"tunnels\", \"is_in_bottleneck\"]\n",
    "\n",
    "fireprot_df = fireprot_df.drop(columns=col_to_drop)\n",
    "\n",
    "# inserting database labels\n",
    "fireprot_df.insert(0, \"DATABASE\", \"FireProt\")\n",
    "\n",
    "# renaming columns\n",
    "dictionary = {\"protein_name\": \"PROTEIN\",\n",
    "              \"uniprot_id\": \"UniProt_ID\",\n",
    "              \"chain\": \"MUTATED_CHAIN\",\n",
    "              \"wild_type\": \"WILD_TYPE_RES\",\n",
    "              \"mutation\": \"MUTATED_RES\",\n",
    "              \"position\": \"POSITION\",\n",
    "              \"method\": \"METHOD\",\n",
    "              \"ddG\": \"∆∆G_H2O_(kcal/mol)\",\n",
    "              \"dTm\": \"∆Tm_(C)\",\n",
    "              \"tm\": \"Tm_(C)\",\n",
    "              \"publication_pubmed\": \"PubMed_ID\",\n",
    "              \"pdb_id\": \"PDB_wild\",\n",
    "              \"technique\": \"MEASURE\"}\n",
    "\n",
    "fireprot_df.rename(columns=dictionary, inplace = True)\n",
    "\n",
    "# drop exact duplicates\n",
    "fireprot_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "# cast experimental data columns to float\n",
    "fireprot_df = cast_to_float(fireprot_df, [\"pH\", \"Tm_(C)\", \"∆Tm_(C)\",\n",
    "                                          \"∆∆G_H2O_(kcal/mol)\",\n",
    "                                          \"PubMed_ID\", \"POSITION\", \"conservation\"])\n",
    "\n",
    "\n",
    "print(fireprot_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a4353",
   "metadata": {},
   "source": [
    "## Combining Protherm, ThermoMut, and Fireprot Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215eb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:  60620\n",
      "Len: 56541\n",
      "Clean df length: 37764\n",
      "Index(['DATABASE', 'PROTEIN', 'UNIPROT_ID', 'MUTATION', 'SOURCE', 'PBD_WILD',\n",
      "       'PBD_CHAIN_MUTATION', 'pH', 'T_(C)', 'Tm_(C)', 'dTm_(C)',\n",
      "       'dH_(kcal/mol)', 'dG_(kcal/mol)', 'ddG_(kcal/mol)',\n",
      "       'ddG_H2O_(kcal/mol)', 'STATE', 'REVERSIBILITY', 'PUBMED_ID',\n",
      "       'REFERENCE', 'MUTATED_CHAIN', 'KINGDOM', 'PBD_MUTANT', 'MEASURE',\n",
      "       'METHOD', 'POSITION', 'WILD_TYPE_RES', 'MUTATED_RES', 'IS_CURATED',\n",
      "       'CONSERVATION', 'NOTES', 'DATASETS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# concatonate all 3 dataframes together\n",
    "all_data_df = pd.concat([protherm_df, thermo_df, fireprot_df], join=\"outer\", ignore_index=True)\n",
    "all_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# raw dataset - no duplicates removed \n",
    "all_data_df.to_csv(\"DBdata/all_data_raw.csv\", header=True, index=False, index_label=False)\n",
    "\n",
    "# removes all exact duplicate rows (dataset has 56,502 values after)\n",
    "print(\"Raw: \",len(all_data_df))\n",
    "all_data_df.drop_duplicates(subset=all_data_df.columns.difference(['DATASET']), keep=\"first\", inplace=True)\n",
    "print(\"Len:\", len(all_data_df))\n",
    "\n",
    "# adding WILD_TYPE_RES, MUTATED_RES, and POSITION columns to combined dataset\n",
    "all_data_df[\"WILD_TYPE_RES\"] = np.nan\n",
    "all_data_df[\"MUTATED_RES\"] = np.nan\n",
    "all_data_df[\"POSITION\"] = np.nan\n",
    "\n",
    "# temporarily replace NaN with \"-\" to avoid errors\n",
    "all_data_df[\"MUTATION\"] = all_data_df[\"MUTATION\"].fillna(\"-\")\n",
    "\n",
    "# replace \",\" so that all multiple points mutations are split by a single space in MUTATION col\n",
    "all_data_df[\"MUTATION\"] = all_data_df[\"MUTATION\"].str.replace(\",\", \" \")\n",
    "all_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fixed_space_col = []\n",
    "for string in all_data_df[\"MUTATION\"]:\n",
    "    fixed_space_col.append(' '.join(string.split()))\n",
    "all_data_df[\"MUTATION\"] = fixed_space_col\n",
    "split_mutation_col = all_data_df[\"MUTATION\"].str.split(\" \")\n",
    "\n",
    "# extricating wild-type (first letter), mutated residue (last letter), and position (inner number) // eg. (L18G)\n",
    "# from cleaned mutation data\n",
    "\n",
    "# returns list with wild-type residue (first letter) from mutation\n",
    "def get_wild_type(split_mutation_column):\n",
    "    wild_type_list = []\n",
    "    w_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            wild_type = \"wild_type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            wild_type = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                w_letters.append(mutation_name[0])\n",
    "                wild_type = \",\".join(w_letters)\n",
    "        wild_type_list.append(wild_type)\n",
    "        w_letters.clear()\n",
    "    return wild_type_list\n",
    "\n",
    "# returns list with mutated residue (last letter) from mutation\n",
    "def get_mutation_type(split_mutation_column):\n",
    "    mutation_list = []\n",
    "    m_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            mutation = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            mutation = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                m_letters.append(mutation_name[-1])\n",
    "                mutation = \",\".join(m_letters)\n",
    "        mutation_list.append(mutation)\n",
    "        m_letters.clear()\n",
    "    return mutation_list\n",
    "\n",
    "# returns list with position (number) from mutation\n",
    "def get_position(split_mutation_column):\n",
    "    position_list = []\n",
    "    p_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            position = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            position = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                p_letters.append(mutation_name[1:-1])\n",
    "                position = \",\".join(p_letters)\n",
    "        position_list.append(position)\n",
    "        p_letters.clear()\n",
    "    return(position_list)\n",
    "\n",
    "# adding data to dataframe\n",
    "all_data_df[\"WILD_TYPE_RES\"] = get_wild_type(split_mutation_col)\n",
    "all_data_df[\"MUTATED_RES\"] = get_mutation_type(split_mutation_col)\n",
    "all_data_df[\"POSITION\"] = get_position(split_mutation_col)\n",
    "\n",
    "all_data_df[\"WILD_TYPE_RES\"] = all_data_df[\"WILD_TYPE_RES\"].str.upper()\n",
    "all_data_df[\"MUTATED_RES\"] = all_data_df[\"MUTATED_RES\"].str.upper()\n",
    "\n",
    "# replacing all \"-\" w/ NaN\n",
    "all_data_df = all_data_df.replace(\"-\", np.nan)\n",
    "\n",
    "# cleaning dataframe\n",
    "all_data_df_clean = all_data_df.copy()\n",
    "\n",
    "# creates seperate dataframe of all duplicated rows\n",
    "dup_df = all_data_df_clean[all_data_df_clean.duplicated(subset=[\"PROTEIN\", \"MUTATED_RES\", \"POSITION\", \"WILD_TYPE_RES\", \"pH\", \"T_(C)\", \"PubMed_ID\"])]\n",
    "\n",
    "# drops duplicated rows from df in order to add back only the rows with the most info\n",
    "all_data_df_clean = all_data_df_clean[~all_data_df_clean.isin(dup_df)].dropna(how = \"all\")\n",
    "\n",
    "# sorting_cols determines duplicated rows\n",
    "sorting_cols = [\"PROTEIN\", \"MUTATED_RES\", \"POSITION\", \"WILD_TYPE_RES\", \"pH\", \"T_(C)\", \"PubMed_ID\"]\n",
    "other_cols = dup_df.columns.difference(sorting_cols)\n",
    "\n",
    "# cleaned duplicate df with only rows with most info\n",
    "dup_df = (dup_df.assign(counts=dup_df.count(axis=1))\n",
    "          .sort_values([\"PROTEIN\", \"MUTATED_RES\", \"POSITION\", \"WILD_TYPE_RES\", \"pH\", \"T_(C)\", \"PubMed_ID\", 'counts'])\n",
    "          .drop_duplicates(sorting_cols, keep='last')\n",
    "          .drop('counts', axis=1))\n",
    "\n",
    "# add back rows with most info to df\n",
    "all_data_df_clean = all_data_df_clean.append(dup_df)\n",
    "print(\"Clean df length: \" + str(len(all_data_df_clean)))\n",
    "\n",
    "# recasting to ensure data types are correct\n",
    "all_data_df_clean = cast_to_float(all_data_df_clean, [\"pH\", \"T_(C)\", \"Tm_(C)\", \"∆Tm_(C)\", \"∆H_(kcal/mol)\",\n",
    "                                          \"∆G_(kcal/mol)\", \"∆∆G_(kcal/mol)\", \"∆∆G_H2O_(kcal/mol)\",\n",
    "                                          \"PubMed_ID\", \"conservation\"])\n",
    "\n",
    "all_data_df_clean = cast_to_string(all_data_df_clean, [\"DATABASE\", \"PROTEIN\", \"UniProt_ID\", \"MUTATION\", \"SOURCE\",\n",
    "                                          \"PDB_wild\", \"PDB_Chain_Mutation\", \"STATE\",\n",
    "                                          \"REVERSIBILITY\", \"KINGDOM\", \"PDB_mutant\",\n",
    "                                          \"MUTATED_CHAIN\", \"MEASURE\", \"METHOD\", \"POSITION\",\n",
    "                                          \"WILD_TYPE_RES\", \"MUTATED_RES\", \"is_curated\", \"datasets\"])\n",
    "\n",
    "# renaming col names for consistency + readibility\n",
    "names = {\"UniProt_ID\": \"UNIPROT_ID\",\n",
    "         \"PDB_wild\": \"PBD_WILD\",\n",
    "         \"PDB_Chain_Mutation\": \"PBD_CHAIN_MUTATION\",\n",
    "         \"PDB_mutant\": \"PBD_MUTANT\",\n",
    "         \"is_curated\": \"IS_CURATED\",\n",
    "         \"datasets\": \"DATASETS\",\n",
    "         \"PubMed_ID\": \"PUBMED_ID\",\n",
    "         \"conservation\": \"CONSERVATION\",\n",
    "         \"∆Tm_(C)\": \"dTm_(C)\",\n",
    "         \"∆H_(kcal/mol)\": \"dH_(kcal/mol)\",\n",
    "         \"∆G_(kcal/mol)\": \"dG_(kcal/mol)\",\n",
    "         \"∆∆G_(kcal/mol)\": \"ddG_(kcal/mol)\",\n",
    "         \"∆∆G_H2O_(kcal/mol)\": \"ddG_H2O_(kcal/mol)\",\n",
    "         \"notes\": \"NOTES\"}\n",
    "\n",
    "# reordering columns for readibility\n",
    "column_order = [\"DATABASE\", \"PROTEIN\", \"UNIPROT_ID\", \"MUTATION\", \"\"]\n",
    "\n",
    "all_data_df_clean.rename(columns=names, inplace = True)\n",
    "\n",
    "all_data_df_clean.to_csv(\"DBdata/all_data_clean.csv\", header=True, index=False, index_label=False)\n",
    "\n",
    "print(all_data_df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784cb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing individual errors\n",
    "\n",
    "all_data_df_clean.iloc[1306, 3] = \"I3C\"\n",
    "all_data_df_clean.iloc[1306, 26] = \"3\"\n",
    "all_data_df_clean.iloc[1306, 27] = \"I\"\n",
    "all_data_df_clean.iloc[1306, 28] = \"C\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab04a1",
   "metadata": {},
   "source": [
    "#### Adding boolean \"Enzyme\" column to indicate if protein is enzyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4666e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add enzyme column (version using UniProtID's)\n",
    "\n",
    "# load column from UniProt datbase w/ all enzyme ID's (35 mil entries)\n",
    "uniprot_35_path = os.path.join(\"DBdata\", \"uniprot-v3.tsv\")\n",
    "uniprot_35_ids = pd.read_csv(uniprot_35_path, usecols=[\"Entry\"], sep='\\t')\n",
    "\n",
    "all_data_enzyme_df = all_data_df_clean.copy()\n",
    "\n",
    "# comparing UniProt ID to find if protein is enzyme\n",
    "# if enzyme, adds TRUE // if not, adds FALSE // if there is no UniProt ID adds NaN\n",
    "enzyme = []\n",
    "\n",
    "for entry in all_data_enzyme_df.iloc[:,2]:\n",
    "    if entry in uniprot_35_ids[\"Entry\"].array:\n",
    "        enzyme.append(True)\n",
    "    else:\n",
    "        if pd.isna(entry):\n",
    "            enzyme.append(np.nan)\n",
    "        else:\n",
    "            enzyme.append(False)\n",
    "    \n",
    "all_data_enzyme_df[\"ENZYME\"] = enzyme\n",
    "\n",
    "all_data_enzyme_df.to_csv(\"DBdata/all_data_clean_enzyme.csv\", header=True, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc8e9f",
   "metadata": {},
   "source": [
    "# Reaction Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e76463",
   "metadata": {},
   "source": [
    "## MuteinDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdce13b",
   "metadata": {},
   "source": [
    "Number of Entries: 485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc94c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Database', 'Wild Type', 'Name', 'Mutations', 'Reaction Type',\n",
      "       'Substrate', 'Product', 'UniProt_ID', 'pH Max', 'pH Min', 'pH Temp [C]',\n",
      "       'Temp Max [C]', 'Temp Min [C]', 'Temp_(C)', 'Mol Weight[g/mol]',\n",
      "       'Num Mutations', 'Organism', 'Tissue', 'pH Buffer', 'Temp Buffer',\n",
      "       'Kingdom', 'K [µM]', 'Activity Value', 'Activity Unit',\n",
      "       'Relative activity [%]', 'Activity Type', 'Inhibitor',\n",
      "       'Expression Host', '# Activities', 'Publication'],\n",
      "      dtype='object')\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "mutein_path = os.path.join(\"DBdata\", \"muteindb.csv\")\n",
    "mutein_df = pd.read_csv(mutein_path, sep=\",\", dtype=\"unicode\")\n",
    "\n",
    "#print(mutein_df.head())\n",
    "col_to_drop = [\"NO\", \"Unnamed: 1\", \"Gen Bank Id\", \"Pdb Id\", \"Contact\", \"pH Opt Value\", \"Temp opt Value [C]\",\n",
    "                \"Signal Seq C\", \"Signal Seq N\", \"Stability +4\", \"Stability -20\", \"Stability Rt\", \"Temp Comment\",\n",
    "                \"pH Comment\", \"Unnamed: 42\" ]\n",
    "mutein_df = mutein_df.drop(columns=col_to_drop)\n",
    "\n",
    "# rename columns\n",
    "dictionary = {\"Uni Prot Id\": \"UniProt_ID\",\n",
    "              \"Temp pH [C]\": \"Temp_(C)\"}\n",
    "\n",
    "mutein_df.rename(columns=dictionary, inplace=True)\n",
    "\n",
    "# add database label\n",
    "mutein_df.insert(0, \"Database\", 'Mutein')\n",
    "print(mutein_df.columns)\n",
    "print(len(mutein_df))\n",
    "\n",
    "# extricating wild-type (first letter), mutation (last letter), and position (inner #) from \"Mutations\" data\n",
    "mutein_df[\"Wild_type_res\"] = np.nan\n",
    "mutein_df[\"Mutated_res\"] = np.nan\n",
    "mutein_df[\"Position\"] = np.nan\n",
    "\n",
    "# temporarily replace NaN with \"-\" to avoid errors\n",
    "mutein_df[\"Mutations\"] = mutein_df[\"Mutations\"].fillna(\"-\")\n",
    "\n",
    "# replace \";\" so that all multiple points mutations are split by a single space in MUTATION col\n",
    "mutein_df[\"Mutations\"] = mutein_df[\"Mutations\"].str.replace(\";\", \" \")\n",
    "\n",
    "fixed_space_col = []\n",
    "for string in mutein_df[\"Mutations\"]:\n",
    "    fixed_space_col.append(' '.join(string.split()))\n",
    "mutein_df[\"Mutations\"] = fixed_space_col\n",
    "split_mutation_col = mutein_df[\"Mutations\"].str.split(\" \")\n",
    "\n",
    "mutein_df[\"Wild_type_res\"] = get_wild_type(split_mutation_col)\n",
    "mutein_df[\"Mutated_res\"] = get_mutation_type(split_mutation_col)\n",
    "mutein_df[\"Position\"] = get_position(split_mutation_col)\n",
    "\n",
    "# replacing all \"-\" w/ NaN\n",
    "mutein_df = mutein_df.replace(\"-\", np.nan)\n",
    "\n",
    "# clean (KM) from \"K [µM]\" list\n",
    "mutein_df[\"K [µM]\"] = mutein_df[\"K [µM]\"].fillna(\"-\")\n",
    "split_k_col = mutein_df[\"K [µM]\"].str.split(\"(\")\n",
    "values = []\n",
    "for string in split_k_col:\n",
    "    val = string[0].strip(\" \")\n",
    "    values.append(val)\n",
    "mutein_df[\"K [µM]\"] = values \n",
    "\n",
    "mutein_df = mutein_df.replace(\"-\", np.nan)\n",
    "\n",
    "# cast type to float\n",
    "mutein_df = cast_to_float(mutein_df, [\"Temp_(C)\", \"pH Max\", \"pH Min\", \"pH Temp [C]\", \"Temp Max [C]\",\n",
    "                                      \"Mol Weight[g/mol]\", \"Num Mutations\", \"K [µM]\"])\n",
    "\n",
    "# save as csv\n",
    "mutein_df.to_csv(\"DBdata/muteindb_clean.csv\", header=True, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aaf50b",
   "metadata": {},
   "source": [
    "#### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e394ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild Type\n",
      "CYP102A1                195\n",
      "CYP3A4                  120\n",
      "CYP2D6                   78\n",
      "PAMO                     31\n",
      "HRP C1                   12\n",
      "Nitrilase, arylaceto     10\n",
      "Nitrilase 2               8\n",
      "MaCel7B                   4\n",
      "TeCel7A                   4\n",
      "HiCel7B                   2\n",
      "P3H type2                 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mutein_df.value_counts(\"Wild Type\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
