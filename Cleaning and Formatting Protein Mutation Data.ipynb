{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17650081",
   "metadata": {},
   "source": [
    "# Cleaning and Formatting Protein Mutation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91bbbe",
   "metadata": {},
   "source": [
    "## ProThermDB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca504b6c",
   "metadata": {},
   "source": [
    "## Dataset Stats\n",
    "\n",
    "Number of Entries = 31,470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457cca0",
   "metadata": {},
   "source": [
    "#### Importing Data and Dropping Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9bf7e460",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PROTEIN', 'UniProt_ID', 'MUTATION', 'SOURCE', 'PDB_wild',\n",
      "       'PDB_Chain_Mutation', 'pH', 'T_(C)', 'Tm_(C)', '∆Tm_(C)',\n",
      "       '∆H_(kcal/mol)', '∆G_(kcal/mol)', '∆∆G_(kcal/mol)',\n",
      "       '∆∆G_H2O_(kcal/mol)', 'STATE', 'REVERSIBILITY', 'PubMed_ID',\n",
      "       'REFERENCE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Jupyter notebook settings to see all data\n",
    "max_rows = None\n",
    "max_cols = None\n",
    "pd.set_option(\"display.max_rows\", max_rows, \"display.max_columns\", max_cols) \n",
    "\n",
    "# load unmodified dataset\n",
    "protherm_path = os.path.join(\"DBdata\", \"ProThermDB_30_JUN_21.tsv\")\n",
    "protherm_df = pd.read_csv(protherm_path,sep='\\t')\n",
    "\n",
    "# removes unneccessary columns\n",
    "col_to_drop = [\"NO\", \"SEC_STR\", \"ASA\", \"KEY_WORDS\", \"AUTHOR\", \"REMARKS\"]\n",
    "protherm_df = protherm_df.drop(columns=col_to_drop)\n",
    "\n",
    "print(protherm_df.columns) \n",
    "\n",
    "# add dataset label\n",
    "protherm_df.insert(0, \"DATABASE\", 'Protherm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35345d6a",
   "metadata": {},
   "source": [
    "#### Functions used to Clean and Cast Column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7703a245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function casts all values in specified columns to floats\n",
    "def cast_to_float(df, col_name_list):\n",
    "    for col in col_name_list:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df\n",
    "\n",
    "# function casts all values in specified columns to strings\n",
    "def cast_to_string(df, col_name_list):\n",
    "    for col in col_name_list:\n",
    "        df[col] = np.where(pd.isnull(df[col]),df[col],df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "# function returns list w/ only mean values of column (e.g 50 (0.01) -> 50)\n",
    "def extract_mean_val_list(column):\n",
    "    column = column.fillna(\"-\")\n",
    "    values = column.str.split(\" \")\n",
    "    mean_vals = []\n",
    "    for val in values:\n",
    "        mean = val[0].strip(\" \")\n",
    "        if \"(\" in mean:\n",
    "            mean = mean[:mean.index(\"(\")]\n",
    "        if \">\" in mean or \"<\" in mean:\n",
    "            mean = \"-\"\n",
    "        if len(mean) == 0:\n",
    "            mean = \"-\"\n",
    "        if \"-\" in mean and mean.index(\"-\") != 0:\n",
    "            nums = mean.split(\"-\")\n",
    "            nums = [float(i) for i in nums]\n",
    "            mean = (nums[0] + nums[1]) / 2\n",
    "        mean_vals.append(mean)\n",
    "    return mean_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e1fdc",
   "metadata": {},
   "source": [
    "#### Cleaning dataframe columns using above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "30a57639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removes all error values from columns w/ experimental error data included\n",
    "protherm_df[\"Tm_(C)\"] = extract_mean_val_list(protherm_df[\"Tm_(C)\"])\n",
    "protherm_df[\"∆Tm_(C)\"] = extract_mean_val_list(protherm_df[\"∆Tm_(C)\"])\n",
    "protherm_df[\"∆H_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆H_(kcal/mol)\"])\n",
    "protherm_df[\"∆G_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆G_(kcal/mol)\"])\n",
    "protherm_df[\"∆∆G_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆∆G_(kcal/mol)\"])\n",
    "protherm_df[\"∆∆G_H2O_(kcal/mol)\"] = extract_mean_val_list(protherm_df[\"∆∆G_H2O_(kcal/mol)\"])\n",
    "\n",
    "# remove \"(Based on UniProt)\"  or \"(Based on UniProt and PBD)\" from MUTATION column\n",
    "split_mutation_col = protherm_df[\"MUTATION\"].str.split(\"(\")\n",
    "names = []\n",
    "for string in split_mutation_col:\n",
    "    mutation_name = string[0].strip(\" \")\n",
    "    names.append(mutation_name)\n",
    "protherm_df[\"MUTATION\"] = names\n",
    "\n",
    "# remove PMID from REFERENCE\n",
    "fixed_reference = []\n",
    "for string in protherm_df[\"REFERENCE\"]:\n",
    "    pmid_index = string.find(\"PMID\")\n",
    "    fixed_reference.append(string[0:pmid_index-1])\n",
    "protherm_df[\"REFERENCE\"] = fixed_reference\n",
    "\n",
    "# clear error DOI strings from \"PubMed_ID\" colum and cast to float\n",
    "correct_ids = []\n",
    "for value in protherm_df[\"PubMed_ID\"]:\n",
    "    if \"DOI\" in value or \"(\" in value:\n",
    "        value = \"-\"\n",
    "    correct_ids.append(value)\n",
    "protherm_df[\"PubMed_ID\"] = correct_ids      \n",
    "\n",
    "# creating MUTATED_CHAIN column\n",
    "protherm_df[\"MUTATED_CHAIN\"] = np.nan\n",
    "\n",
    "# temporarily replace NaN with \"-\" to avoid errors\n",
    "protherm_df[\"PDB_Chain_Mutation\"] = protherm_df[\"PDB_Chain_Mutation\"].fillna(\"-\")\n",
    "\n",
    "# extract mutated chain from PBD_CHAIN_MUTATION and add to MUTATED_CHAIN col\n",
    "protherm_df[\"PDB_Chain_Mutation\"] = protherm_df[\"PDB_Chain_Mutation\"].str.strip(\" \")\n",
    "split_chain_col = protherm_df[\"PDB_Chain_Mutation\"].str.split(\" \")\n",
    "chain = []\n",
    "chain_letters = []\n",
    "for string in split_chain_col:\n",
    "    if \"-\" in string:\n",
    "        to_add_chains = np.nan\n",
    "    else:\n",
    "        for val in string:\n",
    "            index = val.find(\"_\")\n",
    "            letter = val[index+1]\n",
    "            chain_letters.append(letter)\n",
    "            to_add_chains = \",\".join(chain_letters)\n",
    "    chain.append(to_add_chains)\n",
    "    chain_letters.clear()\n",
    "protherm_df[\"MUTATED_CHAIN\"] = chain\n",
    "\n",
    "# replace all \"-\" values with NaN\n",
    "protherm_df = protherm_df.replace(\"-\", np.nan)\n",
    "\n",
    "# cast experimental values + PubMed_ID to floats\n",
    "protherm_df = cast_to_float(protherm_df, [\"pH\", \"T_(C)\", \"Tm_(C)\", \"∆Tm_(C)\", \"∆H_(kcal/mol)\",\n",
    "                                          \"∆G_(kcal/mol)\", \"∆∆G_(kcal/mol)\", \"∆∆G_H2O_(kcal/mol)\",\n",
    "                                          \"PubMed_ID\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731a810",
   "metadata": {},
   "source": [
    "## ThermoMutDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218f650",
   "metadata": {},
   "source": [
    "Number of Entries = 13,348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a3e85b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATABASE', 'PROTEIN', 'SOURCE', 'KINGDOM', 'UniProt_ID', 'PDB_wild',\n",
      "       'PDB_mutant', 'MUTATION', 'MUTATED_CHAIN', 'T_(C)', 'pH', 'MEASURE',\n",
      "       'METHOD', '∆∆G_(kcal/mol)', '∆Tm_(C)', 'REFERENCE', 'PubMed_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load unmodified dataset\n",
    "thermo_path = os.path.join(\"DBdata\", \"thermomutdb.csv\")\n",
    "thermo_df = pd.read_csv(thermo_path)\n",
    "\n",
    "# removing unnecessary columns and add DATABASE column\n",
    "col_to_drop = [\"ID\", \"YEAR\", \"DOI\", \"OTHER_LINKS\", \"HYDRO\",\n",
    "               \"POS\", \"NEG\", \"ACC\", \"DON\", \"ARO\", \"SUL\", \"NEU\", \"SST\", \"RSA\", \"PHI\",\n",
    "               \"PSI\",\"RES_DEPTH\", \"CA_DEPTH\", \"RELATIVE_BFACTOR\", \"BLOSUM62\", \"PAM250\",\n",
    "               \"SEQ_Uniprot\", \"MUTATION_uniprot\", \"MUTATION_pdb\"]\n",
    "\n",
    "thermo_df = thermo_df.drop(columns=col_to_drop)\n",
    "thermo_df.insert(0, \"DATABASE\", 'ThermoMut')\n",
    "\n",
    "# convert temperature units / dTM units to match protherm db (K to C)\n",
    "thermo_df[\"TEMP\"] = thermo_df[\"TEMP\"] - 273.15\n",
    "\n",
    "# renaming and adding columns to match formatting of final dataset\n",
    "dictionary = {\"UNIPROT\": \"UniProt_ID\",\n",
    "        \"TEMP\": \"T_(C)\",\n",
    "        \"ddG\":\"∆∆G_(kcal/mol)\",\n",
    "        \"dTm\": \"∆Tm_(C)\",\n",
    "        \"PMID\": \"PubMed_ID\"}\n",
    "\n",
    "thermo_df.rename(columns=dictionary, inplace = True)\n",
    "print(thermo_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a176d99",
   "metadata": {},
   "source": [
    "## FireProtDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be737423",
   "metadata": {},
   "source": [
    "Number of Entries = 17,136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "15691a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATABASE', 'PROTEIN', 'UniProt_ID', 'PDB_wild', 'MUTATED_CHAIN',\n",
      "       'POSITION', 'WILD_TYPE_RES', 'MUTATED_RES', '∆∆G_H2O_(kcal/mol)',\n",
      "       '∆Tm_(C)', 'is_curated', 'conservation', 'METHOD', 'MEASURE', 'pH',\n",
      "       'Tm_(C)', 'notes', 'PubMed_ID', 'datasets'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "fireprot_path = os.path.join(\"DBdata\", \"fireprotdb_results.csv\")\n",
    "fireprot_df = pd.read_csv(fireprot_path, dtype=\"unicode\")\n",
    "\n",
    "# dropping unneccessary cols\n",
    "col_to_drop = [\"experiment_id\", \"type\", \"derived_type\", \"is_essential\", \"secondary_structure\", \"asa\", \"b_factor\",\n",
    "               \"method_details\", \"technique_details\", \"publication_doi\", \"hsw_job_id\", \"sequence\", \n",
    "               \"interpro_families\", \"correlated_pairs\", \"back_to_consensus\", \"is_in_catalytic_pocket\",\n",
    "               \"tunnels\", \"is_in_bottleneck\"]\n",
    "\n",
    "fireprot_df = fireprot_df.drop(columns=col_to_drop)\n",
    "\n",
    "# inserting database labels\n",
    "fireprot_df.insert(0, \"DATABASE\", \"FireProt\")\n",
    "\n",
    "# renaming columns\n",
    "dictionary = {\"protein_name\": \"PROTEIN\",\n",
    "              \"uniprot_id\": \"UniProt_ID\",\n",
    "              \"chain\": \"MUTATED_CHAIN\",\n",
    "              \"wild_type\": \"WILD_TYPE_RES\",\n",
    "              \"mutation\": \"MUTATED_RES\",\n",
    "              \"position\": \"POSITION\",\n",
    "              \"method\": \"METHOD\",\n",
    "              \"ddG\": \"∆∆G_H2O_(kcal/mol)\",\n",
    "              \"dTm\": \"∆Tm_(C)\",\n",
    "              \"tm\": \"Tm_(C)\",\n",
    "              \"publication_pubmed\": \"PubMed_ID\",\n",
    "              \"pdb_id\": \"PDB_wild\",\n",
    "              \"technique\": \"MEASURE\"}\n",
    "\n",
    "fireprot_df.rename(columns=dictionary, inplace = True)\n",
    "\n",
    "# drop exact duplicates\n",
    "fireprot_df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "# cast experimental data columns to float\n",
    "fireprot_df = cast_to_float(fireprot_df, [\"pH\", \"Tm_(C)\", \"∆Tm_(C)\",\n",
    "                                          \"∆∆G_H2O_(kcal/mol)\",\n",
    "                                          \"PubMed_ID\", \"POSITION\", \"conservation\"])\n",
    "\n",
    "\n",
    "print(fireprot_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a4353",
   "metadata": {},
   "source": [
    "## Combining Protherm, ThermoMut, and Fireprot Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "215eb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:  60620\n",
      "Len: 56541\n",
      "Clean df length: 37764\n",
      "Index(['DATABASE', 'PROTEIN', 'UNIPROT_ID', 'MUTATION', 'SOURCE', 'PBD_WILD',\n",
      "       'PBD_CHAIN_MUTATION', 'pH', 'T_(C)', 'Tm_(C)', 'dTm_(C)',\n",
      "       'dH_(kcal/mol)', 'dG_(kcal/mol)', 'ddG_(kcal/mol)',\n",
      "       'ddG_H2O_(kcal/mol)', 'STATE', 'REVERSIBILITY', 'PUBMED_ID',\n",
      "       'REFERENCE', 'MUTATED_CHAIN', 'KINGDOM', 'PBD_MUTANT', 'MEASURE',\n",
      "       'METHOD', 'POSITION', 'WILD_TYPE_RES', 'MUTATED_RES', 'IS_CURATED',\n",
      "       'CONSERVATION', 'NOTES', 'DATASETS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# concatonate all 3 dataframes together\n",
    "all_data_df = pd.concat([protherm_df, thermo_df, fireprot_df], join=\"outer\", ignore_index=True)\n",
    "all_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# raw dataset - no duplicates removed \n",
    "all_data_df.to_csv(\"DBdata/all_data_raw.csv\", header=True, index=False, index_label=False)\n",
    "\n",
    "# removes all exact duplicate rows (dataset has 56,502 values after)\n",
    "print(\"Raw: \",len(all_data_df))\n",
    "all_data_df.drop_duplicates(subset=all_data_df.columns.difference(['DATASET']), keep=\"first\", inplace=True)\n",
    "print(\"Len:\", len(all_data_df))\n",
    "\n",
    "# adding WILD_TYPE_RES, MUTATED_RES, and POSITION columns to combined dataset\n",
    "all_data_df[\"WILD_TYPE_RES\"] = np.nan\n",
    "all_data_df[\"MUTATED_RES\"] = np.nan\n",
    "all_data_df[\"POSITION\"] = np.nan\n",
    "\n",
    "# temporarily replace NaN with \"-\" to avoid errors\n",
    "all_data_df[\"MUTATION\"] = all_data_df[\"MUTATION\"].fillna(\"-\")\n",
    "\n",
    "# replace \",\" so that all multiple points mutations are split by a single space in MUTATION col\n",
    "all_data_df[\"MUTATION\"] = all_data_df[\"MUTATION\"].str.replace(\",\", \" \")\n",
    "all_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fixed_space_col = []\n",
    "for string in all_data_df[\"MUTATION\"]:\n",
    "    fixed_space_col.append(' '.join(string.split()))\n",
    "all_data_df[\"MUTATION\"] = fixed_space_col\n",
    "split_mutation_col = all_data_df[\"MUTATION\"].str.split(\" \")\n",
    "\n",
    "# extricating wild-type (first letter), mutated residue (last letter), and position (inner number) // eg. (L18G)\n",
    "# from cleaned mutation data\n",
    "\n",
    "# returns list with wild-type residue (first letter) from mutation\n",
    "def get_wild_type(split_mutation_column):\n",
    "    wild_type_list = []\n",
    "    w_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            wild_type = \"wild_type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            wild_type = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                w_letters.append(mutation_name[0])\n",
    "                wild_type = \",\".join(w_letters)\n",
    "        wild_type_list.append(wild_type)\n",
    "        w_letters.clear()\n",
    "    return wild_type_list\n",
    "\n",
    "# returns list with mutated residue (last letter) from mutation\n",
    "def get_mutation_type(split_mutation_column):\n",
    "    mutation_list = []\n",
    "    m_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            mutation = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            mutation = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                m_letters.append(mutation_name[-1])\n",
    "                mutation = \",\".join(m_letters)\n",
    "        mutation_list.append(mutation)\n",
    "        m_letters.clear()\n",
    "    return mutation_list\n",
    "\n",
    "# returns list with position (number) from mutation\n",
    "def get_position(split_mutation_column):\n",
    "    position_list = []\n",
    "    p_letters = []\n",
    "    for string in split_mutation_column:\n",
    "        if \"wild-type\" in string[0]:\n",
    "            position = \"wild-type\"\n",
    "        elif \"-\" in string[0] or len(string) == 0:\n",
    "            position = np.nan\n",
    "        else:\n",
    "            for val in string:\n",
    "                mutation_name = val.strip(\" \")\n",
    "                p_letters.append(mutation_name[1:-1])\n",
    "                position = \",\".join(p_letters)\n",
    "        position_list.append(position)\n",
    "        p_letters.clear()\n",
    "    return(position_list)\n",
    "\n",
    "# adding data to dataframe\n",
    "all_data_df[\"WILD_TYPE_RES\"] = get_wild_type(split_mutation_col)\n",
    "all_data_df[\"MUTATED_RES\"] = get_mutation_type(split_mutation_col)\n",
    "all_data_df[\"POSITION\"] = get_position(split_mutation_col)\n",
    "\n",
    "all_data_df[\"WILD_TYPE_RES\"] = all_data_df[\"WILD_TYPE_RES\"].str.upper()\n",
    "all_data_df[\"MUTATED_RES\"] = all_data_df[\"MUTATED_RES\"].str.upper()\n",
    "\n",
    "# replacing all \"-\" w/ NaN\n",
    "all_data_df = all_data_df.replace(\"-\", np.nan)\n",
    "\n",
    "# cleaning dataframe\n",
    "all_data_df_clean = all_data_df.copy()\n",
    "\n",
    "# creates seperate dataframe of all duplicated rows\n",
    "dup_df = all_data_df_clean[all_data_df_clean.duplicated(subset=[\"PROTEIN\", \"MUTATED_RES\", \"POSITION\", \"WILD_TYPE_RES\", \"pH\", \"T_(C)\", \"PubMed_ID\"])]\n",
    "\n",
    "# drops duplicated rows from df in order to add back only the rows with the most info\n",
    "all_data_df_clean = all_data_df_clean[~all_data_df_clean.isin(dup_df)].dropna(how = \"all\")\n",
    "\n",
    "# sorting_cols determines duplicated rows\n",
    "sorting_cols = [\"PROTEIN\", \"MUTATED_RES\", \"POSITION\", \"WILD_TYPE_RES\", \"pH\", \"T_(C)\", \"PubMed_ID\"]\n",
    "other_cols = dup_df.columns.difference(sorting_cols)\n",
    "\n",
    "# cleaned duplicate df with only rows with most info\n",
    "dup_df = (dup_df.assign(counts=dup_df.count(axis=1))\n",
    "          .sort_values([\"PROTEIN\", \"MUTATED_RES\", \"POSITION\", \"WILD_TYPE_RES\", \"pH\", \"T_(C)\", \"PubMed_ID\", 'counts'])\n",
    "          .drop_duplicates(sorting_cols, keep='last')\n",
    "          .drop('counts', axis=1))\n",
    "\n",
    "# add back rows with most info to df\n",
    "all_data_df_clean = all_data_df_clean.append(dup_df)\n",
    "print(\"Clean df length: \" + str(len(all_data_df_clean)))\n",
    "\n",
    "# recasting to ensure data types are correct\n",
    "all_data_df_clean = cast_to_float(all_data_df_clean, [\"pH\", \"T_(C)\", \"Tm_(C)\", \"∆Tm_(C)\", \"∆H_(kcal/mol)\",\n",
    "                                          \"∆G_(kcal/mol)\", \"∆∆G_(kcal/mol)\", \"∆∆G_H2O_(kcal/mol)\",\n",
    "                                          \"PubMed_ID\", \"conservation\"])\n",
    "\n",
    "all_data_df_clean = cast_to_string(all_data_df_clean, [\"DATABASE\", \"PROTEIN\", \"UniProt_ID\", \"MUTATION\", \"SOURCE\",\n",
    "                                          \"PDB_wild\", \"PDB_Chain_Mutation\", \"STATE\",\n",
    "                                          \"REVERSIBILITY\", \"KINGDOM\", \"PDB_mutant\",\n",
    "                                          \"MUTATED_CHAIN\", \"MEASURE\", \"METHOD\", \"POSITION\",\n",
    "                                          \"WILD_TYPE_RES\", \"MUTATED_RES\", \"is_curated\", \"datasets\"])\n",
    "\n",
    "# renaming col names for consistency + readibility\n",
    "names = {\"UniProt_ID\": \"UNIPROT_ID\",\n",
    "         \"PDB_wild\": \"PBD_WILD\",\n",
    "         \"PDB_Chain_Mutation\": \"PBD_CHAIN_MUTATION\",\n",
    "         \"PDB_mutant\": \"PBD_MUTANT\",\n",
    "         \"is_curated\": \"IS_CURATED\",\n",
    "         \"datasets\": \"DATASETS\",\n",
    "         \"PubMed_ID\": \"PUBMED_ID\",\n",
    "         \"conservation\": \"CONSERVATION\",\n",
    "         \"∆Tm_(C)\": \"dTm_(C)\",\n",
    "         \"∆H_(kcal/mol)\": \"dH_(kcal/mol)\",\n",
    "         \"∆G_(kcal/mol)\": \"dG_(kcal/mol)\",\n",
    "         \"∆∆G_(kcal/mol)\": \"ddG_(kcal/mol)\",\n",
    "         \"∆∆G_H2O_(kcal/mol)\": \"ddG_H2O_(kcal/mol)\",\n",
    "         \"notes\": \"NOTES\"}\n",
    "\n",
    "# reordering columns for readibility\n",
    "column_order = [\"DATABASE\", \"PROTEIN\", \"UNIPROT_ID\", \"MUTATION\", \"\"]\n",
    "\n",
    "all_data_df_clean.rename(columns=names, inplace = True)\n",
    "\n",
    "all_data_df_clean.to_csv(\"DBdata/all_data_clean.csv\", header=True, index=False, index_label=False)\n",
    "\n",
    "print(all_data_df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "784cb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing individual errors\n",
    "\n",
    "all_data_df_clean.iloc[1306, 3] = \"I3C\"\n",
    "all_data_df_clean.iloc[1306, 26] = \"3\"\n",
    "all_data_df_clean.iloc[1306, 27] = \"I\"\n",
    "all_data_df_clean.iloc[1306, 28] = \"C\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab04a1",
   "metadata": {},
   "source": [
    "#### Adding boolean \"Enzyme\" column to indicate if protein is enzyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4666e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-ab6a44b90528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_data_enzyme_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniprot_35_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Entry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0menzyme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/arrays/base.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# calls to ``__getitem__``, which may be slower than necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mcheck_array_indexer\u001b[0;34m(array, indexer)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;31m# In this context, tuples are not considered as array-like, as they have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# a specific meaning in indexing (multi-dimensional indexing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.is_list_like\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.c_is_list_like\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# add enzyme column (version using UniProtID's)\n",
    "\n",
    "# load column from UniProt datbase w/ all enzyme ID's (35 mil entries)\n",
    "uniprot_35_path = os.path.join(\"DBdata\", \"uniprot-v3.tsv\")\n",
    "uniprot_35_ids = pd.read_csv(uniprot_35_path, usecols=[\"Entry\"], sep='\\t')\n",
    "\n",
    "all_data_enzyme_df = all_data_df_clean.copy()\n",
    "\n",
    "# comparing UniProt ID to find if protein is enzyme\n",
    "# if enzyme, adds TRUE // if not, adds FALSE // if there is no UniProt ID adds NaN\n",
    "enzyme = []\n",
    "i = 0\n",
    "for entry in all_data_enzyme_df.iloc[:,2]:\n",
    "    if entry in uniprot_35_ids[\"Entry\"].array:\n",
    "        enzyme.append(True)\n",
    "    else:\n",
    "        if pd.isna(entry):\n",
    "            enzyme.append(np.nan)\n",
    "        else:\n",
    "            enzyme.append(False)\n",
    "    i = i + 1\n",
    "    print(i)\n",
    "    \n",
    "all_data_enzyme_df[\"ENZYME\"] = enzyme\n",
    "\n",
    "all_data_enzyme_df.to_csv(\"DBdata/all_data_clean_enzyme.csv\", header=True, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc8e9f",
   "metadata": {},
   "source": [
    "# Reaction Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e76463",
   "metadata": {},
   "source": [
    "## MuteinDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdce13b",
   "metadata": {},
   "source": [
    "Number of Entries: 485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "cfc94c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Database', 'Wild Type', 'Name', 'Mutations', 'Reaction Type',\n",
      "       'Substrate', 'Product', 'UniProt_ID', 'pH Max', 'pH Min', 'pH Temp [C]',\n",
      "       'Temp Max [C]', 'Temp Min [C]', 'Temp_(C)', 'Mol Weight[g/mol]',\n",
      "       'Num Mutations', 'Organism', 'Tissue', 'pH Buffer', 'Temp Buffer',\n",
      "       'Kingdom', 'K [µM]', 'Activity Value', 'Activity Unit',\n",
      "       'Relative activity [%]', 'Activity Type', 'Inhibitor',\n",
      "       'Expression Host', '# Activities', 'Publication'],\n",
      "      dtype='object')\n",
      "485\n",
      "0        288.000\n",
      "1         40.800\n",
      "2        141.400\n",
      "3         55.000\n",
      "4         39.500\n",
      "5            NaN\n",
      "6         12.800\n",
      "7            NaN\n",
      "8       8000.000\n",
      "9            NaN\n",
      "10      2200.000\n",
      "11      1200.000\n",
      "12      1500.000\n",
      "13      1900.000\n",
      "14       800.000\n",
      "15      3900.000\n",
      "16      2000.000\n",
      "17           NaN\n",
      "18           NaN\n",
      "19           NaN\n",
      "20           NaN\n",
      "21           NaN\n",
      "22           NaN\n",
      "23           NaN\n",
      "24           NaN\n",
      "25           NaN\n",
      "26           NaN\n",
      "27           NaN\n",
      "28           NaN\n",
      "29           NaN\n",
      "30           NaN\n",
      "31           NaN\n",
      "32           NaN\n",
      "33       114.000\n",
      "34           NaN\n",
      "35           NaN\n",
      "36           NaN\n",
      "37           NaN\n",
      "38       769.000\n",
      "39        15.100\n",
      "40        20.000\n",
      "41       320.000\n",
      "42        20.000\n",
      "43           NaN\n",
      "44           NaN\n",
      "45           NaN\n",
      "46           NaN\n",
      "47           NaN\n",
      "48           NaN\n",
      "49           NaN\n",
      "50           NaN\n",
      "51           NaN\n",
      "52           NaN\n",
      "53           NaN\n",
      "54           NaN\n",
      "55           NaN\n",
      "56           NaN\n",
      "57       450.000\n",
      "58           NaN\n",
      "59       530.000\n",
      "60       270.000\n",
      "61       210.000\n",
      "62       310.000\n",
      "63           NaN\n",
      "64       810.000\n",
      "65      2080.000\n",
      "66           NaN\n",
      "67           NaN\n",
      "68           NaN\n",
      "69           NaN\n",
      "70           NaN\n",
      "71           NaN\n",
      "72           NaN\n",
      "73           NaN\n",
      "74           NaN\n",
      "75           NaN\n",
      "76       476.000\n",
      "77           NaN\n",
      "78           NaN\n",
      "79           NaN\n",
      "80           NaN\n",
      "81           NaN\n",
      "82           NaN\n",
      "83           NaN\n",
      "84           NaN\n",
      "85      1346.000\n",
      "86           NaN\n",
      "87           NaN\n",
      "88       350.000\n",
      "89        42.300\n",
      "90           NaN\n",
      "91           NaN\n",
      "92           NaN\n",
      "93           NaN\n",
      "94           NaN\n",
      "95        21.000\n",
      "96           NaN\n",
      "97           NaN\n",
      "98           NaN\n",
      "99           NaN\n",
      "100      340.000\n",
      "101          NaN\n",
      "102       15.800\n",
      "103          NaN\n",
      "104       13.000\n",
      "105       29.800\n",
      "106       37.000\n",
      "107       42.000\n",
      "108       16.700\n",
      "109       17.100\n",
      "110       18.700\n",
      "111        6.600\n",
      "112        4.200\n",
      "113        2.000\n",
      "114       17.000\n",
      "115          NaN\n",
      "116          NaN\n",
      "117      859.000\n",
      "118     2000.000\n",
      "119      648.000\n",
      "120          NaN\n",
      "121          NaN\n",
      "122          NaN\n",
      "123          NaN\n",
      "124     4545.000\n",
      "125          NaN\n",
      "126      540.000\n",
      "127          NaN\n",
      "128          NaN\n",
      "129     1611.000\n",
      "130          NaN\n",
      "131          NaN\n",
      "132          NaN\n",
      "133          NaN\n",
      "134          NaN\n",
      "135          NaN\n",
      "136          NaN\n",
      "137          NaN\n",
      "138          NaN\n",
      "139          NaN\n",
      "140          NaN\n",
      "141          NaN\n",
      "142        8.700\n",
      "143          NaN\n",
      "144          NaN\n",
      "145          NaN\n",
      "146          NaN\n",
      "147      432.000\n",
      "148       28.200\n",
      "149      250.000\n",
      "150      350.000\n",
      "151    30000.000\n",
      "152      500.000\n",
      "153      800.000\n",
      "154      900.000\n",
      "155     1500.000\n",
      "156      170.000\n",
      "157          NaN\n",
      "158          NaN\n",
      "159          NaN\n",
      "160          NaN\n",
      "161          NaN\n",
      "162          NaN\n",
      "163          NaN\n",
      "164          NaN\n",
      "165          NaN\n",
      "166          NaN\n",
      "167          NaN\n",
      "168          NaN\n",
      "169          NaN\n",
      "170          NaN\n",
      "171          NaN\n",
      "172          NaN\n",
      "173          NaN\n",
      "174          NaN\n",
      "175          NaN\n",
      "176          NaN\n",
      "177          NaN\n",
      "178          NaN\n",
      "179          NaN\n",
      "180          NaN\n",
      "181          NaN\n",
      "182          NaN\n",
      "183          NaN\n",
      "184          NaN\n",
      "185          NaN\n",
      "186          NaN\n",
      "187          NaN\n",
      "188          NaN\n",
      "189          NaN\n",
      "190          NaN\n",
      "191          NaN\n",
      "192          NaN\n",
      "193          NaN\n",
      "194       17.360\n",
      "195          NaN\n",
      "196     2175.000\n",
      "197          NaN\n",
      "198        2.000\n",
      "199          NaN\n",
      "200      160.000\n",
      "201      142.000\n",
      "202          NaN\n",
      "203      162.000\n",
      "204        6.000\n",
      "205      117.000\n",
      "206      120.000\n",
      "207      187.000\n",
      "208      188.000\n",
      "209      522.000\n",
      "210        6.100\n",
      "211       14.500\n",
      "212       10.300\n",
      "213        5.100\n",
      "214        3.300\n",
      "215      124.000\n",
      "216      120.000\n",
      "217       27.000\n",
      "218       17.000\n",
      "219       16.000\n",
      "220       14.200\n",
      "221       11.700\n",
      "222       83.400\n",
      "223       18.200\n",
      "224      726.000\n",
      "225      118.000\n",
      "226       19.000\n",
      "227       28.500\n",
      "228          NaN\n",
      "229       54.000\n",
      "230          NaN\n",
      "231       58.200\n",
      "232       53.000\n",
      "233        1.500\n",
      "234       49.000\n",
      "235       68.000\n",
      "236       43.000\n",
      "237       19.000\n",
      "238        1.600\n",
      "239       12.400\n",
      "240       10.500\n",
      "241        2.000\n",
      "242        2.100\n",
      "243        1.400\n",
      "244       26.300\n",
      "245       22.800\n",
      "246        0.140\n",
      "247       29.800\n",
      "248       92.100\n",
      "249        8.500\n",
      "250       49.700\n",
      "251          NaN\n",
      "252       18.900\n",
      "253       30.700\n",
      "254        0.505\n",
      "255        0.680\n",
      "256        3.930\n",
      "257        1.450\n",
      "258       24.100\n",
      "259       60.000\n",
      "260          NaN\n",
      "261       11.000\n",
      "262        0.388\n",
      "263        0.464\n",
      "264          NaN\n",
      "265        7.140\n",
      "266        3.720\n",
      "267        2.630\n",
      "268          NaN\n",
      "269        2.460\n",
      "270          NaN\n",
      "271       14.600\n",
      "272          NaN\n",
      "273          NaN\n",
      "274          NaN\n",
      "275          NaN\n",
      "276       47.000\n",
      "277          NaN\n",
      "278       66.000\n",
      "279          NaN\n",
      "280          NaN\n",
      "281          NaN\n",
      "282          NaN\n",
      "283          NaN\n",
      "284      700.000\n",
      "285      136.500\n",
      "286          NaN\n",
      "287          NaN\n",
      "288          NaN\n",
      "289          NaN\n",
      "290          NaN\n",
      "291          NaN\n",
      "292          NaN\n",
      "293          NaN\n",
      "294          NaN\n",
      "295          NaN\n",
      "296          NaN\n",
      "297          NaN\n",
      "298          NaN\n",
      "299          NaN\n",
      "300          NaN\n",
      "301          NaN\n",
      "302        5.900\n",
      "303          NaN\n",
      "304          NaN\n",
      "305          NaN\n",
      "306          NaN\n",
      "307          NaN\n",
      "308        5.200\n",
      "309          NaN\n",
      "310          NaN\n",
      "311          NaN\n",
      "312          NaN\n",
      "313          NaN\n",
      "314          NaN\n",
      "315      109.600\n",
      "316          NaN\n",
      "317          NaN\n",
      "318          NaN\n",
      "319          NaN\n",
      "320          NaN\n",
      "321        7.900\n",
      "322        3.300\n",
      "323     1400.000\n",
      "324          NaN\n",
      "325          NaN\n",
      "326       47.000\n",
      "327          NaN\n",
      "328       66.000\n",
      "329          NaN\n",
      "330          NaN\n",
      "331          NaN\n",
      "332          NaN\n",
      "333          NaN\n",
      "334      700.000\n",
      "335      136.500\n",
      "336          NaN\n",
      "337          NaN\n",
      "338          NaN\n",
      "339          NaN\n",
      "340          NaN\n",
      "341          NaN\n",
      "342          NaN\n",
      "343          NaN\n",
      "344          NaN\n",
      "345          NaN\n",
      "346          NaN\n",
      "347          NaN\n",
      "348          NaN\n",
      "349          NaN\n",
      "350          NaN\n",
      "351          NaN\n",
      "352        5.900\n",
      "353          NaN\n",
      "354          NaN\n",
      "355          NaN\n",
      "356          NaN\n",
      "357          NaN\n",
      "358        5.200\n",
      "359          NaN\n",
      "360          NaN\n",
      "361          NaN\n",
      "362          NaN\n",
      "363          NaN\n",
      "364          NaN\n",
      "365      109.600\n",
      "366          NaN\n",
      "367          NaN\n",
      "368          NaN\n",
      "369          NaN\n",
      "370          NaN\n",
      "371        7.900\n",
      "372        3.300\n",
      "373     1400.000\n",
      "374       56.300\n",
      "375          NaN\n",
      "376          NaN\n",
      "377          NaN\n",
      "378          NaN\n",
      "379        7.500\n",
      "380          NaN\n",
      "381          NaN\n",
      "382          NaN\n",
      "383      129.700\n",
      "384          NaN\n",
      "385          NaN\n",
      "386          NaN\n",
      "387       68.300\n",
      "388          NaN\n",
      "389       57.200\n",
      "390          NaN\n",
      "391       31.400\n",
      "392          NaN\n",
      "393          NaN\n",
      "394          NaN\n",
      "395          NaN\n",
      "396          NaN\n",
      "397          NaN\n",
      "398          NaN\n",
      "399          NaN\n",
      "400          NaN\n",
      "401          NaN\n",
      "402      530.000\n",
      "403      360.000\n",
      "404      490.000\n",
      "405          NaN\n",
      "406          NaN\n",
      "407          NaN\n",
      "408          NaN\n",
      "409          NaN\n",
      "410    11100.000\n",
      "411    30100.000\n",
      "412          NaN\n",
      "413          NaN\n",
      "414      970.000\n",
      "415          NaN\n",
      "416       91.000\n",
      "417          NaN\n",
      "418          NaN\n",
      "419      560.000\n",
      "420          NaN\n",
      "421       80.000\n",
      "422          NaN\n",
      "423          NaN\n",
      "424          NaN\n",
      "425          NaN\n",
      "426          NaN\n",
      "427          NaN\n",
      "428          NaN\n",
      "429          NaN\n",
      "430          NaN\n",
      "431          NaN\n",
      "432          NaN\n",
      "433          NaN\n",
      "434          NaN\n",
      "435     3000.000\n",
      "436     4000.000\n",
      "437     2500.000\n",
      "438     3800.000\n",
      "439          NaN\n",
      "440          NaN\n",
      "441          NaN\n",
      "442          NaN\n",
      "443          NaN\n",
      "444          NaN\n",
      "445      480.000\n",
      "446      143.000\n",
      "447       54.000\n",
      "448          NaN\n",
      "449          NaN\n",
      "450        4.000\n",
      "451          NaN\n",
      "452          NaN\n",
      "453          NaN\n",
      "454          NaN\n",
      "455          NaN\n",
      "456          NaN\n",
      "457          NaN\n",
      "458     1000.000\n",
      "459        0.000\n",
      "460          NaN\n",
      "461          NaN\n",
      "462          NaN\n",
      "463          NaN\n",
      "464          NaN\n",
      "465          NaN\n",
      "466          NaN\n",
      "467          NaN\n",
      "468          NaN\n",
      "469          NaN\n",
      "470          NaN\n",
      "471          NaN\n",
      "472          NaN\n",
      "473          NaN\n",
      "474          NaN\n",
      "475          NaN\n",
      "476          NaN\n",
      "477          NaN\n",
      "478          NaN\n",
      "479          NaN\n",
      "480          NaN\n",
      "481          NaN\n",
      "482          NaN\n",
      "483          NaN\n",
      "484        0.800\n",
      "Name: K [µM], dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mutein_path = os.path.join(\"DBdata\", \"muteindb.csv\")\n",
    "mutein_df = pd.read_csv(mutein_path, sep=\",\", dtype=\"unicode\")\n",
    "\n",
    "#print(mutein_df.head())\n",
    "col_to_drop = [\"NO\", \"Unnamed: 1\", \"Gen Bank Id\", \"Pdb Id\", \"Contact\", \"pH Opt Value\", \"Temp opt Value [C]\",\n",
    "                \"Signal Seq C\", \"Signal Seq N\", \"Stability +4\", \"Stability -20\", \"Stability Rt\", \"Temp Comment\",\n",
    "                \"pH Comment\", \"Unnamed: 42\" ]\n",
    "mutein_df = mutein_df.drop(columns=col_to_drop)\n",
    "\n",
    "# rename columns\n",
    "dictionary = {\"Uni Prot Id\": \"UniProt_ID\",\n",
    "              \"Temp pH [C]\": \"Temp_(C)\"}\n",
    "\n",
    "mutein_df.rename(columns=dictionary, inplace=True)\n",
    "\n",
    "# add database label\n",
    "mutein_df.insert(0, \"Database\", 'Mutein')\n",
    "print(mutein_df.columns)\n",
    "print(len(mutein_df))\n",
    "\n",
    "# extricating wild-type (first letter), mutation (last letter), and position (inner #) from \"Mutations\" data\n",
    "mutein_df[\"Wild_type_res\"] = np.nan\n",
    "mutein_df[\"Mutated_res\"] = np.nan\n",
    "mutein_df[\"Position\"] = np.nan\n",
    "\n",
    "# temporarily replace NaN with \"-\" to avoid errors\n",
    "mutein_df[\"Mutations\"] = mutein_df[\"Mutations\"].fillna(\"-\")\n",
    "\n",
    "# replace \";\" so that all multiple points mutations are split by a single space in MUTATION col\n",
    "mutein_df[\"Mutations\"] = mutein_df[\"Mutations\"].str.replace(\";\", \" \")\n",
    "\n",
    "fixed_space_col = []\n",
    "for string in mutein_df[\"Mutations\"]:\n",
    "    fixed_space_col.append(' '.join(string.split()))\n",
    "mutein_df[\"Mutations\"] = fixed_space_col\n",
    "split_mutation_col = mutein_df[\"Mutations\"].str.split(\" \")\n",
    "\n",
    "mutein_df[\"Wild_type_res\"] = get_wild_type(split_mutation_col)\n",
    "mutein_df[\"Mutated_res\"] = get_mutation_type(split_mutation_col)\n",
    "mutein_df[\"Position\"] = get_position(split_mutation_col)\n",
    "\n",
    "# replacing all \"-\" w/ NaN\n",
    "mutein_df = mutein_df.replace(\"-\", np.nan)\n",
    "\n",
    "# clean (KM) from \"K [µM]\" list\n",
    "mutein_df[\"K [µM]\"] = mutein_df[\"K [µM]\"].fillna(\"-\")\n",
    "split_k_col = mutein_df[\"K [µM]\"].str.split(\"(\")\n",
    "values = []\n",
    "for string in split_k_col:\n",
    "    val = string[0].strip(\" \")\n",
    "    values.append(val)\n",
    "mutein_df[\"K [µM]\"] = values \n",
    "\n",
    "mutein_df = mutein_df.replace(\"-\", np.nan)\n",
    "\n",
    "# cast type to float\n",
    "mutein_df = cast_to_float(mutein_df, [\"Temp_(C)\", \"pH Max\", \"pH Min\", \"pH Temp [C]\", \"Temp Max [C]\",\n",
    "                                      \"Mol Weight[g/mol]\", \"Num Mutations\", \"K [µM]\"])\n",
    "\n",
    "print(mutein_df[\"K [µM]\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aaf50b",
   "metadata": {},
   "source": [
    "#### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e394ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild Type\n",
      "CYP102A1                195\n",
      "CYP3A4                  120\n",
      "CYP2D6                   78\n",
      "PAMO                     31\n",
      "HRP C1                   12\n",
      "Nitrilase, arylaceto     10\n",
      "Nitrilase 2               8\n",
      "MaCel7B                   4\n",
      "TeCel7A                   4\n",
      "HiCel7B                   2\n",
      "P3H type2                 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mutein_df.value_counts(\"Wild Type\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
